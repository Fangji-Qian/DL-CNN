{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9nxakFm5hUeJ",
        "outputId": "4397d9c8-0beb-4068-b7af-d966928eac75"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "    /content/data\n",
            "    /content/data/Csv\n",
            "    /content/data/Csv/test.csv\n",
            "    /content/data/Csv/train.csv\n",
            "    /content/data/test\n",
            "    /content/data/test/263\n",
            "    /content/data/test/71\n",
            "    /content/data/test/605\n",
            "    /content/data/test/396\n",
            "    /content/data/test/88\n",
            "    /content/data/test/321\n",
            "    /content/data/test/464\n",
            "    /content/data/test/159\n",
            "    /content/data/test/203\n",
            "    /content/data/test/319\n",
            "    /content/data/test/619\n",
            "    /content/data/test/114\n",
            "    /content/data/test/135\n",
            "    /content/data/test/755\n",
            "    /content/data/test/462\n",
            "    /content/data/test/575\n",
            "    /content/data/test/422\n",
            "    /content/data/test/424\n",
            "    /content/data/test/609\n",
            "    /content/data/test/348\n",
            "    /content/data/test/18\n",
            "    /content/data/test/54\n",
            "    /content/data/test/651\n",
            "    /content/data/test/616\n",
            "    /content/data/test/140\n",
            "    /content/data/test/65\n",
            "    /content/data/test/41\n",
            "    /content/data/test/746\n",
            "    /content/data/test/155\n",
            "    /content/data/test/193\n",
            "    /content/data/test/696\n",
            "    /content/data/test/544\n",
            "    /content/data/test/302\n",
            "    /content/data/test/186\n",
            "    /content/data/test/470\n",
            "    /content/data/test/177\n",
            "    /content/data/test/691\n",
            "    /content/data/test/652\n",
            "    /content/data/test/686\n",
            "    /content/data/test/429\n",
            "    /content/data/test/675\n",
            "    /content/data/test/747\n",
            "    /content/data/test/57\n",
            "    /content/data/test/457\n",
            "    /content/data/test/740\n",
            "    /content/data/test/165\n",
            "    /content/data/test/73\n",
            "    /content/data/test/453\n",
            "    /content/data/test/280\n",
            "    /content/data/test/26\n",
            "    /content/data/test/623\n",
            "    /content/data/test/373\n",
            "    /content/data/test/162\n",
            "    /content/data/test/738\n",
            "    /content/data/test/507\n",
            "    /content/data/test/122\n",
            "    /content/data/test/485\n",
            "    /content/data/test/546\n",
            "    /content/data/test/323\n",
            "    /content/data/test/560\n",
            "    /content/data/test/163\n",
            "    /content/data/test/111\n",
            "    /content/data/test/39\n",
            "    /content/data/test/87\n",
            "    /content/data/test/672\n",
            "    /content/data/test/284\n",
            "    /content/data/test/185\n",
            "    /content/data/test/189\n",
            "    /content/data/test/545\n",
            "    /content/data/test/48\n",
            "    /content/data/test/690\n",
            "    /content/data/test/83\n",
            "    /content/data/test/628\n",
            "    /content/data/test/674\n",
            "    /content/data/test/495\n",
            "    /content/data/test/629\n",
            "    /content/data/test/751\n",
            "    /content/data/test/255\n",
            "    /content/data/test/216\n",
            "    /content/data/test/110\n",
            "    /content/data/test/474\n",
            "    /content/data/test/758\n",
            "    /content/data/test/364\n",
            "    /content/data/test/448\n",
            "    /content/data/test/515\n",
            "    /content/data/test/169\n",
            "    /content/data/test/656\n",
            "    /content/data/test/477\n",
            "    /content/data/test/195\n",
            "    /content/data/test/220\n",
            "    /content/data/test/352\n",
            "    /content/data/test/701\n",
            "    /content/data/test/634\n",
            "    /content/data/test/562\n",
            "    /content/data/test/481\n",
            "    /content/data/test/25\n",
            "    /content/data/test/99\n",
            "    /content/data/test/617\n",
            "    /content/data/test/175\n",
            "    /content/data/test/725\n",
            "    /content/data/test/384\n",
            "    /content/data/test/215\n",
            "    /content/data/test/383\n",
            "    /content/data/test/168\n",
            "    /content/data/test/360\n",
            "    /content/data/test/430\n",
            "    /content/data/test/699\n",
            "    /content/data/test/180\n",
            "    /content/data/test/603\n",
            "    /content/data/test/335\n",
            "    /content/data/test/20\n",
            "    /content/data/test/578\n",
            "    /content/data/test/454\n",
            "    /content/data/test/368\n",
            "    /content/data/test/441\n",
            "    /content/data/test/60\n",
            "    /content/data/test/427\n",
            "    /content/data/test/338\n",
            "    /content/data/test/226\n",
            "    /content/data/test/158\n",
            "    /content/data/test/678\n",
            "    /content/data/test/345\n",
            "    /content/data/test/238\n",
            "    /content/data/test/52\n",
            "    /content/data/test/497\n",
            "    /content/data/test/188\n",
            "    /content/data/test/363\n",
            "    /content/data/test/590\n",
            "    /content/data/test/113\n",
            "    /content/data/test/381\n",
            "    /content/data/test/741\n",
            "    /content/data/test/698\n",
            "    /content/data/test/576\n",
            "    /content/data/test/315\n",
            "    /content/data/test/191\n",
            "    /content/data/train\n",
            "    /content/data/train/263\n",
            "    /content/data/train/71\n",
            "    /content/data/train/605\n",
            "    /content/data/train/396\n",
            "    /content/data/train/88\n",
            "    /content/data/train/321\n",
            "    /content/data/train/464\n",
            "    /content/data/train/159\n",
            "    /content/data/train/203\n",
            "    /content/data/train/319\n",
            "    /content/data/train/619\n",
            "    /content/data/train/114\n",
            "    /content/data/train/135\n",
            "    /content/data/train/755\n",
            "    /content/data/train/462\n",
            "    /content/data/train/575\n",
            "    /content/data/train/422\n",
            "    /content/data/train/424\n",
            "    /content/data/train/609\n",
            "    /content/data/train/348\n",
            "    /content/data/train/18\n",
            "    /content/data/train/54\n",
            "    /content/data/train/651\n",
            "    /content/data/train/616\n",
            "    /content/data/train/140\n",
            "    /content/data/train/65\n",
            "    /content/data/train/41\n",
            "    /content/data/train/746\n",
            "    /content/data/train/155\n",
            "    /content/data/train/193\n",
            "    /content/data/train/696\n",
            "    /content/data/train/544\n",
            "    /content/data/train/302\n",
            "    /content/data/train/186\n",
            "    /content/data/train/470\n",
            "    /content/data/train/177\n",
            "    /content/data/train/691\n",
            "    /content/data/train/652\n",
            "    /content/data/train/686\n",
            "    /content/data/train/429\n",
            "    /content/data/train/675\n",
            "    /content/data/train/747\n",
            "    /content/data/train/57\n",
            "    /content/data/train/457\n",
            "    /content/data/train/740\n",
            "    /content/data/train/165\n",
            "    /content/data/train/73\n",
            "    /content/data/train/453\n",
            "    /content/data/train/280\n",
            "    /content/data/train/26\n",
            "    /content/data/train/623\n",
            "    /content/data/train/373\n",
            "    /content/data/train/162\n",
            "    /content/data/train/738\n",
            "    /content/data/train/507\n",
            "    /content/data/train/122\n",
            "    /content/data/train/485\n",
            "    /content/data/train/546\n",
            "    /content/data/train/323\n",
            "    /content/data/train/560\n",
            "    /content/data/train/163\n",
            "    /content/data/train/111\n",
            "    /content/data/train/39\n",
            "    /content/data/train/87\n",
            "    /content/data/train/672\n",
            "    /content/data/train/284\n",
            "    /content/data/train/185\n",
            "    /content/data/train/189\n",
            "    /content/data/train/545\n",
            "    /content/data/train/48\n",
            "    /content/data/train/690\n",
            "    /content/data/train/83\n",
            "    /content/data/train/628\n",
            "    /content/data/train/674\n",
            "    /content/data/train/495\n",
            "    /content/data/train/629\n",
            "    /content/data/train/751\n",
            "    /content/data/train/255\n",
            "    /content/data/train/216\n",
            "    /content/data/train/110\n",
            "    /content/data/train/474\n",
            "    /content/data/train/758\n",
            "    /content/data/train/364\n",
            "    /content/data/train/448\n",
            "    /content/data/train/515\n",
            "    /content/data/train/169\n",
            "    /content/data/train/656\n",
            "    /content/data/train/477\n",
            "    /content/data/train/195\n",
            "    /content/data/train/220\n",
            "    /content/data/train/352\n",
            "    /content/data/train/701\n",
            "    /content/data/train/634\n",
            "    /content/data/train/562\n",
            "    /content/data/train/481\n",
            "    /content/data/train/25\n",
            "    /content/data/train/99\n",
            "    /content/data/train/617\n",
            "    /content/data/train/175\n",
            "    /content/data/train/725\n",
            "    /content/data/train/384\n",
            "    /content/data/train/215\n",
            "    /content/data/train/383\n",
            "    /content/data/train/168\n",
            "    /content/data/train/360\n",
            "    /content/data/train/430\n",
            "    /content/data/train/699\n",
            "    /content/data/train/180\n",
            "    /content/data/train/603\n",
            "    /content/data/train/335\n",
            "    /content/data/train/20\n",
            "    /content/data/train/578\n",
            "    /content/data/train/454\n",
            "    /content/data/train/368\n",
            "    /content/data/train/441\n",
            "    /content/data/train/60\n",
            "    /content/data/train/427\n",
            "    /content/data/train/338\n",
            "    /content/data/train/226\n",
            "    /content/data/train/158\n",
            "    /content/data/train/678\n",
            "    /content/data/train/345\n",
            "    /content/data/train/238\n",
            "    /content/data/train/52\n",
            "    /content/data/train/497\n",
            "    /content/data/train/188\n",
            "    /content/data/train/363\n",
            "    /content/data/train/590\n",
            "    /content/data/train/113\n",
            "    /content/data/train/381\n",
            "    /content/data/train/741\n",
            "    /content/data/train/698\n",
            "    /content/data/train/576\n",
            "    /content/data/train/315\n",
            "    /content/data/train/191\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!mkdir -p /content/data\n",
        "\n",
        "!unzip -q '/content/drive/MyDrive/43031/Test/archive.zip' -d '/content/data'\n",
        "\n",
        "\n",
        "!find /content/data -maxdepth 2 | sed 's/^/    /'\n",
        "\n",
        "\n",
        "data_dir = '/content/data'\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "\n",
        "csv_dir     = '/content/data/Csv'\n",
        "train_csv   = os.path.join(csv_dir, 'train.csv')\n",
        "test_csv    = os.path.join(csv_dir, 'test.csv')\n",
        "\n",
        "img_root    = '/content/data'\n",
        "train_img   = os.path.join(img_root, 'train')\n",
        "test_img    = os.path.join(img_root, 'test')\n",
        "\n",
        "print('Train images dirs:', sorted(os.listdir(train_img))[:5], '…')\n",
        "print('Test  images dirs:', sorted(os.listdir(test_img))[:5], '…')\n",
        "print('CSV files:', os.listdir(csv_dir))\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224,224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
        "])\n",
        "train_ds = datasets.ImageFolder(train_img, transform=transform)\n",
        "test_ds  = datasets.ImageFolder(test_img,  transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=32, shuffle=True)\n",
        "test_loader  = DataLoader(test_ds,  batch_size=32, shuffle=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VSWxnanniLNs",
        "outputId": "4bd3bc8b-f4c4-45e1-9267-a4190d267735"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train images dirs: ['110', '111', '113', '114', '122'] …\n",
            "Test  images dirs: ['110', '111', '113', '114', '122'] …\n",
            "CSV files: ['test.csv', 'train.csv']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import random_split, DataLoader\n",
        "\n",
        "total = len(train_ds)\n",
        "n_train = int(0.8 * total)\n",
        "n_val   = total - n_train\n",
        "train_subset, val_subset = random_split(train_ds, [n_train, n_val])\n",
        "\n",
        "train_loader = DataLoader(train_subset, batch_size=32, shuffle=True,  num_workers=2)\n",
        "val_loader   = DataLoader(val_subset,   batch_size=32, shuffle=False, num_workers=2)\n",
        "test_loader  = DataLoader(test_ds,      batch_size=32, shuffle=False, num_workers=2)\n",
        "\n",
        "import torch\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "import torch.nn as nn\n",
        "class CustomCNN(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super().__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3,32,3,padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
        "            nn.Conv2d(32,64,3,padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
        "            nn.Conv2d(64,128,3,padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(128*28*28,512), nn.ReLU(), nn.Dropout(0.5),\n",
        "            nn.Linear(512,num_classes)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.classifier(self.features(x))\n",
        "\n",
        "from torchvision import models\n",
        "def get_effnet_b2(fine_tune, num_classes):\n",
        "    model = models.efficientnet_b2(pretrained=True)\n",
        "    if not fine_tune:\n",
        "        for p in model.parameters(): p.requires_grad=False\n",
        "    else:\n",
        "\n",
        "        total = len(list(model.parameters()))\n",
        "        for i, p in enumerate(model.parameters()):\n",
        "            p.requires_grad = (i/total) >= 0.6\n",
        "    in_f = model.classifier[1].in_features\n",
        "    model.classifier = nn.Sequential(nn.Dropout(0.3), nn.Linear(in_f, num_classes))\n",
        "    return model\n",
        "\n",
        "import torch.optim as optim\n",
        "\n",
        "def train_and_eval(model, epochs=5):\n",
        "    model.to(device)\n",
        "    opt = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-4)\n",
        "    crit = nn.CrossEntropyLoss()\n",
        "    best_val = 0\n",
        "    for _ in range(epochs):\n",
        "        model.train()\n",
        "        for x,y in train_loader:\n",
        "            x,y = x.to(device), y.to(device)\n",
        "            opt.zero_grad()\n",
        "            loss = crit(model(x), y)\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "        model.eval()\n",
        "        correct = total = 0\n",
        "        with torch.no_grad():\n",
        "            for x,y in val_loader:\n",
        "                x,y = x.to(device), y.to(device)\n",
        "                preds = model(x).argmax(dim=1)\n",
        "                correct += (preds==y).sum().item()\n",
        "                total += y.size(0)\n",
        "        best_val = max(best_val, correct/total*100)\n",
        "\n",
        "    def acc(dl):\n",
        "        model.eval()\n",
        "        c = t = 0\n",
        "        with torch.no_grad():\n",
        "            for x,y in dl:\n",
        "                x,y = x.to(device), y.to(device)\n",
        "                preds = model(x).argmax(dim=1)\n",
        "                c += (preds==y).sum().item()\n",
        "                t += y.size(0)\n",
        "        return c/t*100\n",
        "    return acc(train_loader), best_val, acc(test_loader)\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "num_cls = len(train_ds.dataset.classes) if hasattr(train_ds, 'dataset') else len(train_ds.classes)\n",
        "results = []\n",
        "# CNN-1\n",
        "r1 = train_and_eval(CustomCNN(num_cls))\n",
        "results.append(['CNN-1 (Custom)', *r1])\n",
        "# CNN-2\n",
        "r2 = train_and_eval(get_effnet_b2(fine_tune=False, num_classes=num_cls))\n",
        "results.append(['CNN-2 (EffNet-B2 Frozen)', *r2])\n",
        "# CNN-3\n",
        "r3 = train_and_eval(get_effnet_b2(fine_tune=True,  num_classes=num_cls))\n",
        "results.append(['CNN-3 (EffNet-B2 FT)', *r3])\n",
        "\n",
        "df = pd.DataFrame(results, columns=['Model','Train Acc (%)','Val Acc (%)','Test Acc (%)'])\n",
        "print(df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "alOjzoZxm_UA",
        "outputId": "d746de99-8161-4ff7-ff20-29134cc5c64b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B2_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B2_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/efficientnet_b2_rwightman-c35c1473.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b2_rwightman-c35c1473.pth\n",
            "100%|██████████| 35.2M/35.2M [00:00<00:00, 141MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                      Model  Train Acc (%)  Val Acc (%)  Test Acc (%)\n",
            "0            CNN-1 (Custom)      42.453101     8.135528      8.062460\n",
            "1  CNN-2 (EffNet-B2 Frozen)      32.116194    24.693721     23.326960\n",
            "2      CNN-3 (EffNet-B2 FT)      84.499426    52.526799     49.840663\n"
          ]
        }
      ]
    }
  ]
}